{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"\nimport cv2\nimport numpy as np\nfrom keras.models import *\nfrom keras.layers import *\nfrom keras.optimizers import *\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler,EarlyStopping\nfrom keras import backend as keras\nfrom PIL import Image,ImageDraw\nfrom skimage import filters,img_as_float\nfrom skimage.io import imsave\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n#import os\n#for dirname, _, filenames in os.walk('/kaggle/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import xml.etree.ElementTree as ET\nimport os\n#fig, axs = plt.subplots(1,2)\nimages_train={}\nfor dirname, _, filenames in os.walk('/kaggle/input/fracture/fracture/training'):\n    for filename in filenames:\n        img1=Image.open(os.path.join(dirname,filename)).convert('RGB')\n        index=os.path.splitext(filename)[0]\n        images_train[index]=img1\n        #print(img1.size)\n#axs[0].imshow(images_train['0'])\n\nimage_train_annotations={}\nfor dirname, _, filenames in os.walk('/kaggle/input/fracture/fracture/training_annotations'):\n    for filename in filenames:\n        tree=ET.parse(os.path.join(dirname,filename))\n        root=tree.getroot()\n        index_=os.path.splitext(filename)[0]\n        img=images_train[index_]\n        width,height=img.size\n        #print(width,height,type(img))\n        if img == None:\n            del images_train[index_]\n            continue\n        image=Image.new(mode='1',size=(width,height),color=0)\n        image1=Image.new(mode='1',size=(width,height),color=1)\n        #print(type(image))\n        try:\n            for objects in root.iter('bndbox'):\n                start1,end1=(int(objects.find('xmin').text),int(objects.find('ymin').text))\n                start2,end2=(int(objects.find('xmax').text),int(objects.find('ymax').text))\n                #print(start1,end1,start2,end2)\n                image1=image1.crop((start1,end1,start2,end2))\n                image.paste(image1,(start1,end1,start2,end2))\n                #print(type(image))\n            image_train_annotations[index_]=image\n        except AttributeError:\n            del images_train[index_]\n        #print(image)\nplt.imshow(image_train_annotations['1'])\n        \n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#cv expects a pointer to draw a rect\n#np.copy isn't working expecting ptr<cv:Umat>\n#if images_train == image_train_annotations:\n#    print(\"doomed\")\nfn = lambda x : 1 if x > 240 else 0\ntrain_data=[images_train[i] for i in sorted(images_train)]\ntrain_annotations=[image_train_annotations[i] for i in sorted(image_train_annotations)]\n\nfig, axs = plt.subplots(1,2)\naxs[0].imshow(train_data[0])\n\nplt.imshow(train_annotations[0])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"images_valid={}\nfor dirname, _, filenames in os.walk('/kaggle/input/fracture/fracture/validation'):\n    for filename in filenames:\n        img1=Image.open(os.path.join(dirname,filename)).convert('RGB')\n        index=os.path.splitext(filename)[0]\n        images_valid[index]=img1\n#axs[0].imshow(images_train['0'])\n\nimage_valid_annotations={}\n\nfor dirname, _, filenames in os.walk('/kaggle/input/fracture/fracture/validation_annotations'):\n    for filename in filenames:\n        tree=ET.parse(os.path.join(dirname,filename))\n        root=tree.getroot()\n        index_=os.path.splitext(filename)[0]\n        img=images_valid[index_]\n        width,height=img.size\n        #print(width,height,type(img))\n        if img == None:\n            del images_train[index_]\n            continue\n        image=Image.new(mode='1',size=(width,height),color=0)\n        image1=Image.new(mode='1',size=(width,height),color=1)\n        #print(type(image))\n        try:\n            for objects in root.iter('bndbox'):\n                start1,end1=(int(objects.find('xmin').text),int(objects.find('ymin').text))\n                start2,end2=(int(objects.find('xmax').text),int(objects.find('ymax').text))\n                #print(start1,end1,start2,end2)\n                image1=image1.crop((start1,end1,start2,end2))\n                image.paste(image1,(start1,end1,start2,end2))\n                #print(type(image))\n            image_valid_annotations[index_]=image\n        except AttributeError:\n            del images_train[index_]\n        #print(image)\n#plt.imshow(image_valid_annotations['1'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fn = lambda x : 1 if x > 240 else 0\nvalid_data=[images_valid[i] for i in sorted(images_valid)]\nvalid_annotations=[image_valid_annotations[i] for i in sorted(image_valid_annotations)]\nprint(len(valid_annotations))\n\nfig, axs = plt.subplots(1,2)\naxs[0].imshow(valid_data[2])\n\nplt.imshow(valid_annotations[2])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"import tensorflow as tf","metadata":{"trusted":true}},{"cell_type":"markdown","source":"def mean_iou(self,y_true, y_pred):\n        prec = []\n        for t in np.arange(0.5, 1.0, 0.05):\n            y_pred_ = tf.to_int32(y_pred > t)\n            score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n            K.get_session().run(tf.local_variables_initializer())\n            with tf.control_dependencies([up_opt]):\n                score = tf.identity(score)\n            prec.append(score)\n        return K.mean(K.stack(prec), axis=0)\n\ndef unet(pretrained_weights = None,input_size = (128,128,1)):\n    inputs = Input(input_size)\n    s = Lambda(lambda x: x / 255) (inputs)\n\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (s)\n    c1 = Dropout(0.1) (c1)\n    c1 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c1)\n    p1 = MaxPooling2D((2, 2)) (c1)\n\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p1)\n    c2 = Dropout(0.1) (c2)\n    c2 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c2)\n    p2 = MaxPooling2D((2, 2)) (c2)\n\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p2)\n    c3 = Dropout(0.2) (c3)\n    c3 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c3)\n    p3 = MaxPooling2D((2, 2)) (c3)\n\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p3)\n    c4 = Dropout(0.2) (c4)\n    c4 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c4)\n    p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (p4)\n    c5 = Dropout(0.3) (c5)\n    c5 = Conv2D(256, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c5)\n\n    u6 = Conv2DTranspose(128, (2, 2), strides=(2, 2), padding='same') (c5)\n    u6 = concatenate([u6, c4])\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u6)\n    c6 = Dropout(0.2) (c6)\n    c6 = Conv2D(128, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c6)\n\n    u7 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c6)\n    u7 = concatenate([u7, c3])\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u7)\n    c7 = Dropout(0.2) (c7)\n    c7 = Conv2D(64, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c7)\n\n    u8 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c7)\n    u8 = concatenate([u8, c2])\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u8)\n    c8 = Dropout(0.1) (c8)\n    c8 = Conv2D(32, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c8)\n\n    u9 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c8)\n    u9 = concatenate([u9, c1], axis=3)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (u9)\n    c9 = Dropout(0.1) (c9)\n    c9 = Conv2D(16, (3, 3), activation='elu', kernel_initializer='he_normal', padding='same') (c9)\n\n    outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n\n    model = Model(inputs=[inputs], outputs=[outputs])\n\n    return(model)\n\n","metadata":{"trusted":true}},{"cell_type":"markdown","source":"import keras.preprocessing.image as image\nimage_data_gen = image.ImageDataGenerator(rotation_range = 40, horizontal_flip = True,\n                                          vertical_flip = True, zoom_range = 0.2,\n                                          shear_range = 0.2,width_shift_range = 0.2,\n                                          height_shift_range = 0.2)\nmask_data_gen = image.ImageDataGenerator(rotation_range = 40, horizontal_flip = True,\n                                          vertical_flip = True, zoom_range = 0.2,\n                                          shear_range = 0.2,width_shift_range = 0.2,\n                                          height_shift_range = 0.2)\nvalidimg_data_gen = image.ImageDataGenerator()\nvalidmask_data_gen = image.ImageDataGenerator()\n","metadata":{"trusted":true}},{"cell_type":"code","source":"current='/kaggle/working'\nos.mkdir(os.path.join(current,'valid_images'))\nos.mkdir(os.path.join(current,'valid_annotations'))\nos.mkdir(os.path.join(current,'train_annotations'))\nos.mkdir(os.path.join(current,'train_images'))\nos.mkdir(os.path.join(current,'valid_images/present'))\nos.mkdir(os.path.join(current,'valid_annotations/present'))\nos.mkdir(os.path.join(current,'train_images/present'))\nos.mkdir(os.path.join(current,'train_annotations/present'))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nfor dirname,_,filenames in os.walk(os.path.join(current,'train_images/present')):\n    for file in filenames:\n        os.remove(os.path.join(dirname,file))\n\nfor dirname,_,filenames in os.walk(os.path.join(current,'train_annotations/present')):\n    for file in filenames:\n        os.remove(os.path.join(dirname,file))\n        \nfor dirname,_,filenames in os.walk(os.path.join(current,'valid_images/present')):\n    for file in filenames:\n        os.remove(os.path.join(dirname,file))\n#os.mkdir(os.path.join(current,'train_images'))\nfor dirname,_,filenames in os.walk(os.path.join(current,'valid_annotations/present')):\n    for file in filenames:\n        os.remove(os.path.join(dirname,file))\n\n\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install -U keras_segmentation","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from imageio import imwrite\n\ntrain_dir=os.path.join(current,'train_images/present')\ntrain_an_dir=os.path.join(current,'train_annotations/present')\nvalid_dir=os.path.join(current,'valid_images/present')\nvalid_an_dir=os.path.join(current,'valid_annotations/present')\nfn = lambda x : 1 if x > 240 else 0\nfor i,v in enumerate(train_data):\n    if v is not None:\n        cv2.imwrite(os.path.join(train_dir,str(i)+'.png'),img_as_float(np.float32(v)))\n\n#print(type())\nfor i,v in enumerate(train_annotations):\n    print(v)\n    if v is not None:\n        val = filters.threshold_otsu(np.float32(v))\n        mask = np.float32(v)< val\n        plt.imshow(img_as_float(mask))\n        #print(img_as_float(mask))\n        cv2.imwrite(os.path.join(train_an_dir,str(i)+'.png'),img_as_float(mask))\nfor i,v in enumerate(valid_data):\n    if v is not None:\n        cv2.imwrite(os.path.join(valid_dir,str(i)+'.png'),img_as_float(np.float32(v)))\n\nfor i,v in enumerate(valid_annotations):\n    print(v)\n    if v is not None:\n        val = filters.threshold_otsu(np.float32(v))\n        mask = np.float32(v)< val\n        plt.imshow(mask)\n        cv2.imwrite(os.path.join(valid_an_dir,str(i)+'.png'),img_as_float(mask))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"valid=[]\nfor dirname,_,filenames in os.walk(train_an_dir):\n    for file in filenames:\n        valid.append(file)\nfor dirname,_,filenames in os.walk(train_dir):\n    for file in filenames:\n        if file not in valid:\n            print(file)\n            os.remove(os.path.join(train_dir,file))\n            \n            \n        \n    \nvalid=[]\nfor dirname,_,filenames in os.walk(valid_an_dir):\n    for file in filenames:\n        valid.append(file)\nfor dirname,_,filenames in os.walk(valid_dir):\n    for file in filenames:\n        if file not in valid:\n            print(file)\n            os.remove(os.path.join(valid_dir,file))\n","metadata":{}},{"cell_type":"markdown","source":"\nimage_array_gen = image_data_gen.flow_from_directory(directory='/kaggle/working/train_images', class_mode = None,\n                                   target_size = (128,128),color_mode='grayscale',batch_size=10)\nmask_array_gen = mask_data_gen.flow_from_directory(directory='/kaggle/working/train_annotations', class_mode = None,\n                                   target_size = (128,128),color_mode='grayscale',batch_size=10)\nvalid_image_array_gen = validimg_data_gen.flow_from_directory(directory= '/kaggle/working/valid_images', class_mode = None,\n                                   target_size = (128,128),color_mode='grayscale',batch_size=10)\nvalid_mask_array_gen = validmask_data_gen.flow_from_directory(directory= '/kaggle/working/valid_annotations', class_mode = None,\n                                   target_size = (128,128),color_mode='grayscale',batch_size=10)\ntrain_generator = zip(image_array_gen, mask_array_gen)\nvalid_generator = zip(valid_image_array_gen, valid_mask_array_gen)","metadata":{"trusted":true}},{"cell_type":"markdown","source":"!pip install tf-nightly","metadata":{}},{"cell_type":"markdown","source":"\n\n\n\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n \n  try:\n    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n    model = unet()\n    model.compile(optimizer='adam', loss='binary_crossentropy' ,metrics=['binary_accuracy'])\n    earlystopper = EarlyStopping(patience=5, verbose=10)\n    checkpointer = ModelCheckpoint('/kaggle/working/modelunet.h5', verbose=1, save_best_only=True)\n    results = model.fit_generator(train_generator, epochs=5, callbacks=[earlystopper, checkpointer])\n  except RuntimeError as e:\n    # Virtual devices must be set before GPUs have been initialized\n    print(e)\n","metadata":{}},{"cell_type":"markdown","source":"\ntpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect()\n\ntpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n\nwith tpu_strategy.scope():\n    model = unet()\n    model.compile(optimizer='adam', loss='binary_crossentropy' ,metrics=['binary_accuracy'])\n    earlystopper = EarlyStopping(patience=5, verbose=1)\n    checkpointer = ModelCheckpoint('/kaggle/working/modelunet.h5', verbose=1, save_best_only=True)\nresults = model.fit_generator(train_generator, epochs=5, \n                        callbacks=[earlystopper, checkpointer])","metadata":{"trusted":true}},{"cell_type":"markdown","source":"model = unet()\nmodel.compile(optimizer='adam', loss='binary_crossentropy' ,metrics=['binary_accuracy'])\nearlystopper = EarlyStopping(patience=5, verbose=1)\ncheckpointer = ModelCheckpoint('/kaggle/working/modelunet.h5', verbose=1, save_best_only=True)\nresults = model.fit_generator(train_generator, epochs=40, steps_per_epoch=100,\n                        callbacks=[earlystopper, checkpointer])","metadata":{"trusted":true}},{"cell_type":"markdown","source":"from skimage.transform import resize\ndef prediction(imagePath):\n    img=cv2.imread(imagePath)\n    x_test= np.zeros((1, 128,128,1), dtype=np.uint8)\n    img=resize(img,(128,128,1),mode='constant',preserve_range=True)\n    x_test[0]=img\n    preds_test= model.predict(x_test, verbose=1)\n    #preds_test = (preds_test > 0.5).astype(np.uint8)\n    mask=preds_test[0]\n    for i in range(mask.shape[0]):\n        for j in range(mask.shape[1]):\n            if mask[i][j] == 1:\n                mask[i][j] = 255\n            else:\n                mask[i][j] = 0\n    merged_image = cv2.merge((mask,mask,mask))\n    print(preds_test[1])\n    plt.imshow(merged_image)","metadata":{"trusted":true}},{"cell_type":"markdown","source":"prediction('/kaggle/working/valid_images/present/2.png')\n#plt.imshow(PIL.Image.open('/kaggle/working/valid_images/present/2.png'))","metadata":{"trusted":true}},{"cell_type":"markdown","source":"i=Image.open('/kaggle/working/train_annotations/present/40.tiff')\nplt.imshow(i.convert('L').point(fn,mode='1'))","metadata":{"trusted":true}},{"cell_type":"code","source":"from keras_segmentation.models.unet import resnet50_unet as res_unet\n\nmodel = res_unet(n_classes=2 ,  input_height=256, input_width=256  )\nmodel.train( \n    train_images =  train_dir,\n    train_annotations = train_an_dir,\n    checkpoints_path = current+'/experimodel',\n   epochs=9\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"out = model.predict_segmentation(\n\tinp=valid_dir+\"/3.png\", \n\tout_fname=valid_dir+\"/predict/output.png\" \n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(out)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(Image.open(valid_dir+\"/3.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.imshow(Image.open(valid_an_dir+\"/3.png\"))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}